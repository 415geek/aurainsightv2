# app.py
# Streamlit: è¾“å…¥é¤å…åœ°å€/åº—å -> Google Places åŒ¹é… -> ç”¨æˆ·ç¡®è®¤ -> æ‹‰å–å…¬å¼€æ•°æ®
# (Google/Yelp/Census+TIGER/NOAA+Meteostat/WalkScoreå¯é€‰) -> è°ƒç”¨ OpenAI ç”Ÿæˆæ·±åº¦æŠ¥å‘Š -> å¤šè¯­è¨€ -> å¯¼å‡ºPDF
#
# âœ… é‡ç‚¹ï¼šå¤©æ°”å·²æ”¹ä¸º NOAA + Meteostatï¼ˆæ— éœ€æ³¨å†Œã€ç¨³å®šã€é€‚åˆåˆ†æï¼‰
#
# ---------------------------
# å®‰è£…ä¾èµ–
# ---------------------------
# pip install streamlit requests python-dateutil pandas reportlab meteostat
# å¯é€‰ï¼ˆæ›´æ¼‚äº®PDFï¼‰: pip install markdown2 weasyprint
#
# ---------------------------
# ç¯å¢ƒå˜é‡
# ---------------------------
# GOOGLE_MAPS_API_KEY=...
# YELP_API_KEY=...
# OPENAI_API_KEY=...
# OPENAI_MODEL=gpt-4o-mini   (æŒ‰ä½ è´¦å·å¯ç”¨æ¨¡å‹è°ƒæ•´)
# CENSUS_API_KEY=...         (å¯é€‰ï¼šæ— keyä¹Ÿèƒ½ç”¨éƒ¨åˆ†Censusï¼Œä½†å»ºè®®æœ‰)
# WALKSCORE_API_KEY=...      (å¯é€‰)
#
# ---------------------------
# å…è´£å£°æ˜ï¼ˆäº§å“çº§åšæ³•ï¼‰
# ---------------------------
# - 1mi/3mi äººå£ç­‰â€œåŠå¾„å•†åœˆâ€æ˜¯åŸºäº Census Tract/County å¯†åº¦è¿‘ä¼¼ä¼°ç®—ï¼Œä¸ç­‰åŒäºç²¾ç¡®ç¯å½¢å åŠ ç»Ÿè®¡ã€‚
# - ç«å“æ¸…å•æ¥è‡ª Yelp/Google å‘¨è¾¹æ£€ç´¢ï¼Œå¯èƒ½æ¼æ‰æœªæ”¶å½•æˆ–æ–°åº—ã€‚
#
# Author: you + me (ä¸¥è°¨ç‰ˆ)

import os
import json
import math
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import requests
import pandas as pd
import streamlit as st

from meteostat import Point, Daily

# -----------------------------
# Streamlit config
# -----------------------------
st.set_page_config(page_title="AuraInsight Â· é¤å…å•†åœˆä¸å¢é•¿åˆ†æ", layout="wide")

# -----------------------------
# ENV
# -----------------------------
GOOGLE_MAPS_API_KEY = os.getenv("GOOGLE_MAPS_API_KEY", "")
YELP_API_KEY = os.getenv("YELP_API_KEY", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
CENSUS_API_KEY = os.getenv("CENSUS_API_KEY", "")
WALKSCORE_API_KEY = os.getenv("WALKSCORE_API_KEY", "")

USER_AGENT = "AuraInsight-Analyzer/1.0"

DEFAULT_RADII_MI = [1, 3]  # æ ·æ¿ï¼š1 mile / 3 mile


# -----------------------------
# Errors
# -----------------------------
class APIError(Exception):
    pass


# -----------------------------
# HTTP helpers + cache
# -----------------------------
def _req_json(
    method: str,
    url: str,
    headers: Optional[dict] = None,
    params: Optional[dict] = None,
    json_body: Optional[dict] = None,
    timeout: int = 30,
    retries: int = 2,
    backoff: float = 1.4,
) -> dict:
    headers = headers or {}
    headers.setdefault("User-Agent", USER_AGENT)

    last_err = None
    for i in range(retries + 1):
        try:
            r = requests.request(
                method=method.upper(),
                url=url,
                headers=headers,
                params=params,
                json=json_body,
                timeout=timeout,
            )
            if r.status_code == 429:
                time.sleep(backoff ** (i + 1))
                continue
            if r.status_code >= 400:
                raise APIError(f"{url} -> HTTP {r.status_code}: {r.text[:500]}")
            if "application/json" in r.headers.get("content-type", ""):
                return r.json()
            # NOAAæœ‰æ—¶ text/json
            return json.loads(r.text)
        except Exception as e:
            last_err = e
            time.sleep(backoff ** (i + 1))
    raise APIError(f"Request failed after retries: {url} | {repr(last_err)}")


@st.cache_data(show_spinner=False, ttl=60 * 60 * 24)  # 24h
def cached_http_json(method: str, url: str, params_key: str, headers_key: str, body_key: str) -> dict:
    params = json.loads(params_key) if params_key else None
    headers = json.loads(headers_key) if headers_key else None
    body = json.loads(body_key) if body_key else None
    return _req_json(method, url, headers=headers, params=params, json_body=body)


def http_json_cached(method: str, url: str, params: Optional[dict] = None, headers: Optional[dict] = None, body: Optional[dict] = None) -> dict:
    return cached_http_json(
        method=method,
        url=url,
        params_key=json.dumps(params or {}, sort_keys=True),
        headers_key=json.dumps(headers or {}, sort_keys=True),
        body_key=json.dumps(body or {}, sort_keys=True),
    )


# -----------------------------
# Google Places
# -----------------------------
@dataclass
class PlaceCandidate:
    name: str
    place_id: str
    address: str
    lat: float
    lng: float
    types: List[str]
    rating: Optional[float]
    user_ratings_total: Optional[int]


def google_text_search(query: str) -> List[PlaceCandidate]:
    if not GOOGLE_MAPS_API_KEY:
        raise APIError("Missing GOOGLE_MAPS_API_KEY")
    url = "https://maps.googleapis.com/maps/api/place/textsearch/json"
    params = {"query": query, "key": GOOGLE_MAPS_API_KEY}
    data = http_json_cached("GET", url, params=params)

    results = data.get("results", []) or []
    out: List[PlaceCandidate] = []
    for r in results[:10]:
        loc = (r.get("geometry") or {}).get("location") or {}
        out.append(
            PlaceCandidate(
                name=r.get("name", "") or "",
                place_id=r.get("place_id", "") or "",
                address=r.get("formatted_address", "") or "",
                lat=float(loc.get("lat", 0.0) or 0.0),
                lng=float(loc.get("lng", 0.0) or 0.0),
                types=r.get("types") or [],
                rating=r.get("rating"),
                user_ratings_total=r.get("user_ratings_total"),
            )
        )
    return out


def google_place_details(place_id: str) -> dict:
    if not GOOGLE_MAPS_API_KEY:
        raise APIError("Missing GOOGLE_MAPS_API_KEY")
    url = "https://maps.googleapis.com/maps/api/place/details/json"
    fields = ",".join(
        [
            "name",
            "place_id",
            "formatted_address",
            "geometry",
            "types",
            "rating",
            "user_ratings_total",
            "opening_hours",
            "website",
            "formatted_phone_number",
            "price_level",
            "business_status",
        ]
    )
    params = {"place_id": place_id, "fields": fields, "key": GOOGLE_MAPS_API_KEY, "language": "en"}
    data = http_json_cached("GET", url, params=params)
    if data.get("status") != "OK":
        raise APIError(f"Google Place Details failed: {data.get('status')} {data.get('error_message','')}")
    return data["result"]


def google_nearby_search(lat: float, lng: float, radius_m: int, keyword: str = "", type_: str = "restaurant") -> List[dict]:
    if not GOOGLE_MAPS_API_KEY:
        raise APIError("Missing GOOGLE_MAPS_API_KEY")
    url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json"
    params = {"location": f"{lat},{lng}", "radius": radius_m, "type": type_, "key": GOOGLE_MAPS_API_KEY}
    if keyword:
        params["keyword"] = keyword
    data = http_json_cached("GET", url, params=params)
    return (data.get("results") or [])[:20]


# -----------------------------
# Yelp Fusion
# -----------------------------
def yelp_headers() -> dict:
    if not YELP_API_KEY:
        raise APIError("Missing YELP_API_KEY")
    return {"Authorization": f"Bearer {YELP_API_KEY}", "User-Agent": USER_AGENT}


def yelp_business_search(name: str, lat: float, lng: float) -> Optional[dict]:
    url = "https://api.yelp.com/v3/businesses/search"
    params = {
        "term": name,
        "latitude": lat,
        "longitude": lng,
        "limit": 5,
        "sort_by": "best_match",
    }
    data = http_json_cached("GET", url, params=params, headers=yelp_headers())
    businesses = data.get("businesses") or []
    return businesses[0] if businesses else None


def yelp_business_details(business_id: str) -> dict:
    url = f"https://api.yelp.com/v3/businesses/{business_id}"
    return http_json_cached("GET", url, headers=yelp_headers())


def yelp_business_reviews(business_id: str) -> dict:
    url = f"https://api.yelp.com/v3/businesses/{business_id}/reviews"
    return http_json_cached("GET", url, headers=yelp_headers())


def yelp_competitors(lat: float, lng: float, radius_m: int = 4800, categories: Optional[str] = None) -> List[dict]:
    url = "https://api.yelp.com/v3/businesses/search"
    params = {
        "latitude": lat,
        "longitude": lng,
        "radius": min(radius_m, 40000),
        "limit": 20,
        "sort_by": "rating",
    }
    if categories:
        params["categories"] = categories
    data = http_json_cached("GET", url, params=params, headers=yelp_headers())
    return data.get("businesses") or []


# -----------------------------
# Weather: NOAA + Meteostat
# -----------------------------
def noaa_points(lat: float, lng: float) -> dict:
    url = f"https://api.weather.gov/points/{lat:.4f},{lng:.4f}"
    headers = {"User-Agent": USER_AGENT, "Accept": "application/geo+json"}
    return http_json_cached("GET", url, headers=headers)


def noaa_forecast(lat: float, lng: float) -> dict:
    p = noaa_points(lat, lng)
    forecast_url = (p.get("properties") or {}).get("forecast")
    if not forecast_url:
        raise APIError("NOAA points missing forecast url")
    headers = {"User-Agent": USER_AGENT, "Accept": "application/geo+json"}
    return http_json_cached("GET", forecast_url, headers=headers)


@st.cache_data(show_spinner=False, ttl=60 * 60 * 24)
def meteostat_daily(lat: float, lng: float, days: int = 365) -> pd.DataFrame:
    # Meteostat: å­¦æœ¯çº§å†å²æ•°æ®ï¼ˆæ— éœ€keyï¼‰
    end = datetime.utcnow()
    start = end - timedelta(days=days)
    location = Point(lat, lng)
    df = Daily(location, start, end).fetch()
    if df is None or df.empty:
        return pd.DataFrame()
    df = df.reset_index()
    # å­—æ®µï¼štavg/tmin/tmax/prcp/snow/wspd/...
    return df


def summarize_weather(df: pd.DataFrame) -> dict:
    if df is None or df.empty:
        return {
            "days": 0,
            "rain_days": None,
            "heavy_rain_days": None,
            "hot_days": None,
            "cold_days": None,
            "avg_tavg_c": None,
            "total_prcp_mm": None,
        }

    days = len(df)
    # prcp: mm (Meteostat)
    rain_days = int((df["prcp"].fillna(0) > 0.5).sum())
    heavy_rain_days = int((df["prcp"].fillna(0) > 10).sum())
    # tmax/tmin: Â°C
    hot_days = int((df["tmax"].fillna(-999) > 30).sum())   # >86Â°F
    cold_days = int((df["tmin"].fillna(999) < 5).sum())    # <41Â°F
    avg_tavg = float(df["tavg"].dropna().mean()) if df["tavg"].notna().any() else None
    total_prcp = float(df["prcp"].fillna(0).sum())

    return {
        "days": days,
        "rain_days": rain_days,
        "heavy_rain_days": heavy_rain_days,
        "hot_days": hot_days,
        "cold_days": cold_days,
        "avg_tavg_c": avg_tavg,
        "total_prcp_mm": total_prcp,
    }


# -----------------------------
# Census: FCC -> GEOIDs -> ACS + TIGER land area
# -----------------------------
def fcc_block_geoid(lat: float, lng: float) -> dict:
    # FCC Census Block API: lat/lon -> state/county/tract/block FIPS
    url = "https://geo.fcc.gov/api/census/block/find"
    params = {"latitude": lat, "longitude": lng, "format": "json"}
    return http_json_cached("GET", url, params=params)


def tiger_tract_land_area(state: str, county: str, tract: str) -> Optional[int]:
    # TIGERweb: get ALAND for tract (m^2)
    # layer: Census Tracts
    # https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/Tracts_Blocks/MapServer/2/query
    url = "https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/Tracts_Blocks/MapServer/2/query"
    geoid = f"{state}{county}{tract}"
    params = {
        "where": f"GEOID='{geoid}'",
        "outFields": "ALAND,GEOID,NAME",
        "f": "json",
    }
    data = http_json_cached("GET", url, params=params)
    feats = data.get("features") or []
    if not feats:
        return None
    attrs = feats[0].get("attributes") or {}
    aland = attrs.get("ALAND")
    return int(aland) if aland is not None else None


def tiger_county_land_area(state: str, county: str) -> Optional[int]:
    # TIGERweb Counties layer
    url = "https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/County/MapServer/0/query"
    geoid = f"{state}{county}"
    params = {
        "where": f"GEOID='{geoid}'",
        "outFields": "ALAND,GEOID,NAME",
        "f": "json",
    }
    data = http_json_cached("GET", url, params=params)
    feats = data.get("features") or []
    if not feats:
        return None
    attrs = feats[0].get("attributes") or {}
    aland = attrs.get("ALAND")
    return int(aland) if aland is not None else None


def acs_tract_profile(state: str, county: str, tract: str) -> dict:
    # ACS 5-year: tract-level key vars
    # variables:
    # B01003_001E total population
    # B19013_001E median household income
    # DP05_0037PE Asian alone percent (DP05_0037PE)
    # DP05_0071PE Hispanic percent (DP05_0071PE)
    # DP05_0033PE White alone percent (DP05_0033PE)
    # DP02_0001E households (DP02_0001E)
    #
    # DP* tables are in /profile endpoint.
    base = "https://api.census.gov/data/2022/acs/acs5/profile"
    vars_ = [
        "DP05_0001E",   # Total population (profile)
        "DP02_0001E",   # Households
        "DP03_0062E",   # Median household income (approx; DP03 varies, this is "Median household income" in profile)
        "DP05_0033PE",  # White %
        "DP05_0037PE",  # Asian %
        "DP05_0071PE",  # Hispanic %
        "NAME",
    ]
    params = {
        "get": ",".join(vars_),
        "for": f"tract:{tract}",
        "in": f"state:{state} county:{county}",
    }
    if CENSUS_API_KEY:
        params["key"] = CENSUS_API_KEY

    data = http_json_cached("GET", base, params=params)
    # First row headers, second row values
    if not isinstance(data, list) or len(data) < 2:
        raise APIError("Census ACS response unexpected")
    headers = data[0]
    values = data[1]
    out = dict(zip(headers, values))
    return out


def safe_int(x: Any) -> Optional[int]:
    try:
        if x is None or x == "":
            return None
        return int(float(x))
    except Exception:
        return None


def safe_float(x: Any) -> Optional[float]:
    try:
        if x is None or x == "":
            return None
        return float(x)
    except Exception:
        return None


def estimate_radius_population(
    radius_miles: float,
    tract_pop: Optional[int],
    tract_aland_m2: Optional[int],
    county_pop: Optional[int],
    county_aland_m2: Optional[int],
) -> Tuple[Optional[int], str]:
    """
    åŠå¾„äººå£è¿‘ä¼¼ï¼š
    - 1miï¼šä¼˜å…ˆç”¨ tract å¯†åº¦ä¼°ç®—å¹¶ä¸Šé™=tract_pop
    - 3miï¼šä¼˜å…ˆç”¨ county å¯†åº¦ä¼°ç®—ï¼ˆèŒƒå›´æ›´å¤§ï¼‰ï¼Œé¿å…tractè¿‡å°å¯¼è‡´å¤±çœŸ
    """
    r_m = radius_miles * 1609.344
    area_circle = math.pi * (r_m ** 2)

    def density(pop: Optional[int], aland: Optional[int]) -> Optional[float]:
        if pop is None or aland is None or aland <= 0:
            return None
        return pop / aland  # people per m^2

    if radius_miles <= 1.5:
        d = density(tract_pop, tract_aland_m2)
        if d is None:
            return None, "density_missing"
        est = int(d * area_circle)
        if tract_pop is not None:
            est = min(est, tract_pop)
        return max(est, 0), "tract_density"
    else:
        d = density(county_pop, county_aland_m2)
        if d is None:
            return None, "density_missing"
        est = int(d * area_circle)
        return max(est, 0), "county_density"


def census_bundle_from_latlng(lat: float, lng: float) -> dict:
    fcc = fcc_block_geoid(lat, lng)
    block = (fcc.get("Block") or {})
    fips = block.get("FIPS")
    if not fips or len(fips) < 11:
        raise APIError("FCC did not return valid FIPS")
    # FIPS: SSCCCTTTTTTBBBB -> take needed pieces
    state = fips[0:2]
    county = fips[2:5]
    tract = fips[5:11]

    acs = acs_tract_profile(state, county, tract)

    tract_pop = safe_int(acs.get("DP05_0001E"))
    households = safe_int(acs.get("DP02_0001E"))
    med_income = safe_int(acs.get("DP03_0062E"))
    pct_white = safe_float(acs.get("DP05_0033PE"))
    pct_asian = safe_float(acs.get("DP05_0037PE"))
    pct_hisp = safe_float(acs.get("DP05_0071PE"))

    tract_aland = tiger_tract_land_area(state, county, tract)
    county_aland = tiger_county_land_area(state, county)

    # county populationï¼šç”¨ ACS5ï¼ˆnon-profile endpointï¼‰æ›´ç¨³ï¼Œä½†è¿™é‡Œç”¨ profile county ä¹Ÿè¡Œ
    # ä¸ºç®€åŒ–ï¼šç”¨åŒprofileæ¥å£ countyå±‚
    base = "https://api.census.gov/data/2022/acs/acs5/profile"
    params = {"get": "DP05_0001E,NAME", "for": f"county:{county}", "in": f"state:{state}"}
    if CENSUS_API_KEY:
        params["key"] = CENSUS_API_KEY
    county_data = http_json_cached("GET", base, params=params)
    county_pop = None
    if isinstance(county_data, list) and len(county_data) >= 2:
        headers = county_data[0]
        values = county_data[1]
        row = dict(zip(headers, values))
        county_pop = safe_int(row.get("DP05_0001E"))

    return {
        "fcc": fcc,
        "state_fips": state,
        "county_fips": county,
        "tract": tract,
        "tract_name": acs.get("NAME"),
        "tract_pop": tract_pop,
        "households": households,
        "median_household_income": med_income,
        "pct_white": pct_white,
        "pct_asian": pct_asian,
        "pct_hispanic": pct_hisp,
        "tract_aland_m2": tract_aland,
        "county_pop": county_pop,
        "county_aland_m2": county_aland,
    }


# -----------------------------
# WalkScore (optional)
# -----------------------------
def walkscore(lat: float, lng: float, address: str) -> Optional[dict]:
    if not WALKSCORE_API_KEY:
        return None
    url = "https://api.walkscore.com/score"
    params = {
        "format": "json",
        "address": address,
        "lat": lat,
        "lon": lng,
        "transit": 1,
        "bike": 1,
        "wsapikey": WALKSCORE_API_KEY,
    }
    try:
        return http_json_cached("GET", url, params=params)
    except Exception:
        return None


# -----------------------------
# OpenAI (via REST) - generate & translate
# -----------------------------
def openai_headers() -> dict:
    if not OPENAI_API_KEY:
        raise APIError("Missing OPENAI_API_KEY")
    return {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}


def openai_chat(prompt_system: str, prompt_user: str, temperature: float = 0.3, max_tokens: int = 3500) -> str:
    """
    Uses Chat Completions compatible endpoint. If your account requires Responses API,
    you can switch. This one works for many setups.
    """
    url = "https://api.openai.com/v1/chat/completions"
    body = {
        "model": OPENAI_MODEL,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "messages": [
            {"role": "system", "content": prompt_system},
            {"role": "user", "content": prompt_user},
        ],
    }
    data = _req_json("POST", url, headers=openai_headers(), json_body=body, timeout=90, retries=1)
    choices = data.get("choices") or []
    if not choices:
        raise APIError("OpenAI returned no choices")
    return (choices[0].get("message") or {}).get("content") or ""


def translate_text(text: str, target_lang: str) -> str:
    # target_lang: "zh" or "en"
    if target_lang not in ("zh", "en"):
        return text
    sys = "You are a professional business report translator. Preserve structure, headings, tables, [FACT]/[INFERENCE]/[ASSUMPTION]/[STRATEGY] tags. Do not add or remove content."
    if target_lang == "zh":
        user = f"Translate to Simplified Chinese:\n\n{text}"
    else:
        user = f"Translate to English:\n\n{text}"
    return openai_chat(sys, user, temperature=0.1, max_tokens=3500)


# -----------------------------
# Report builder: data bundle -> prompt -> report markdown
# -----------------------------
def miles_to_meters(mi: float) -> int:
    return int(mi * 1609.344)


def build_data_bundle(place: dict) -> dict:
    name = place.get("name", "")
    address = place.get("formatted_address", "")
    geom = (place.get("geometry") or {}).get("location") or {}
    lat = float(geom.get("lat", 0.0) or 0.0)
    lng = float(geom.get("lng", 0.0) or 0.0)

    # Yelp
    yelp_match = None
    yelp_details = None
    yelp_reviews = None
    competitors_yelp = []
    try:
        if YELP_API_KEY:
            yelp_match = yelp_business_search(name, lat, lng)
            if yelp_match and yelp_match.get("id"):
                yelp_details = yelp_business_details(yelp_match["id"])
                yelp_reviews = yelp_business_reviews(yelp_match["id"])
            competitors_yelp = yelp_competitors(lat, lng, radius_m=miles_to_meters(3))
    except Exception as e:
        competitors_yelp = competitors_yelp or []
        yelp_details = yelp_details or None
        yelp_reviews = yelp_reviews or None

    # Google nearby competitors (backup)
    competitors_google = []
    try:
        competitors_google = google_nearby_search(lat, lng, radius_m=miles_to_meters(3), type_="restaurant")
    except Exception:
        competitors_google = []

    # Census
    census = {}
    try:
        census = census_bundle_from_latlng(lat, lng)
    except Exception as e:
        census = {"error": str(e)}

    # Radius estimates
    radius_stats = []
    for r in DEFAULT_RADII_MI:
        est_pop, method = estimate_radius_population(
            radius_miles=r,
            tract_pop=census.get("tract_pop"),
            tract_aland_m2=census.get("tract_aland_m2"),
            county_pop=census.get("county_pop"),
            county_aland_m2=census.get("county_aland_m2"),
        )
        radius_stats.append({"radius_miles": r, "est_population": est_pop, "method": method})

    # Weather: NOAA forecast + Meteostat history
    noaa_fc = None
    try:
        noaa_fc = noaa_forecast(lat, lng)
    except Exception as e:
        noaa_fc = {"error": str(e)}

    hist_df = meteostat_daily(lat, lng, days=365)
    weather_summary = summarize_weather(hist_df)

    # WalkScore optional
    ws = None
    try:
        ws = walkscore(lat, lng, address)
    except Exception:
        ws = None

    return {
        "place": place,
        "lat": lat,
        "lng": lng,
        "google": {
            "rating": place.get("rating"),
            "user_ratings_total": place.get("user_ratings_total"),
            "types": place.get("types"),
            "price_level": place.get("price_level"),
            "business_status": place.get("business_status"),
            "phone": place.get("formatted_phone_number"),
            "website": place.get("website"),
            "opening_hours": (place.get("opening_hours") or {}).get("weekday_text"),
        },
        "yelp": {
            "match": yelp_match,
            "details": yelp_details,
            "reviews": yelp_reviews,
            "competitors": competitors_yelp,
        },
        "competitors_google": competitors_google,
        "census": census,
        "radius_stats": radius_stats,
        "weather": {
            "noaa_forecast": noaa_fc,
            "meteostat_days": 365,
            "meteostat_summary": weather_summary,
        },
        "walkscore": ws,
        # (å¯æ‰©å±•) safegraph / crime / traffic / POI density
    }


def compact_competitors(yelp_list: List[dict], google_list: List[dict]) -> List[dict]:
    """
    ç»™æ¨¡å‹çš„ç«å“è¾“å…¥å¿…é¡»â€œçŸ­è€Œç»“æ„åŒ–â€ï¼Œå¦åˆ™promptçˆ†ç‚¸ã€‚
    """
    out = []
    # Yelp top 10
    for b in (yelp_list or [])[:10]:
        out.append(
            {
                "source": "yelp",
                "name": b.get("name"),
                "rating": b.get("rating"),
                "review_count": b.get("review_count"),
                "price": b.get("price"),
                "distance_m": b.get("distance"),
                "categories": [c.get("title") for c in (b.get("categories") or [])[:2]],
            }
        )
    # Google top 10
    for r in (google_list or [])[:10]:
        out.append(
            {
                "source": "google",
                "name": r.get("name"),
                "rating": r.get("rating"),
                "user_ratings_total": r.get("user_ratings_total"),
                "vicinity": r.get("vicinity"),
                "types": (r.get("types") or [])[:3],
            }
        )
    # å»é‡ï¼ˆæŒ‰nameï¼‰
    seen = set()
    uniq = []
    for x in out:
        n = (x.get("name") or "").strip().lower()
        if not n:
            continue
        if n in seen:
            continue
        seen.add(n)
        uniq.append(x)
    return uniq[:18]


def compact_noaa_forecast(noaa: dict) -> List[dict]:
    """
    NOAA forecast periods -> ç®€åŒ–ï¼ˆæœªæ¥3-6ä¸ªæ—¶æ®µï¼‰
    """
    props = (noaa or {}).get("properties") or {}
    periods = props.get("periods") or []
    simple = []
    for p in periods[:6]:
        simple.append(
            {
                "name": p.get("name"),
                "temperature": p.get("temperature"),
                "temperatureUnit": p.get("temperatureUnit"),
                "windSpeed": p.get("windSpeed"),
                "shortForecast": p.get("shortForecast"),
            }
        )
    return simple


def make_report_prompt(bundle: dict, lang: str = "zh") -> Tuple[str, str]:
    place = bundle["place"]
    name = place.get("name", "")
    address = place.get("formatted_address", "")
    lat, lng = bundle["lat"], bundle["lng"]

    competitors = compact_competitors(bundle["yelp"].get("competitors") or [], bundle.get("competitors_google") or [])
    noaa_simple = compact_noaa_forecast(bundle["weather"].get("noaa_forecast") or {})
    weather_summary = bundle["weather"].get("meteostat_summary") or {}

    census = bundle.get("census") or {}
    radius_stats = bundle.get("radius_stats") or []

    # ç”¨äºâ€œæ ·æ¿é€»è¾‘â€è¾“å‡ºçš„ç³»ç»Ÿæç¤º
    system = f"""
ä½ æ˜¯ä¸€ä¸ªâ€œé¤å…å•†åœˆä¸å¢é•¿åˆ†æâ€ä¸“å®¶é¡¾é—®ï¼Œè¾“å‡ºå¿…é¡»åƒä¸“ä¸šå’¨è¯¢æŠ¥å‘Šï¼šç»“æ„æ¸…æ™°ã€æ¨ç†ä¸¥è°¨ã€å¯æ‰§è¡Œã€‚
å¼ºåˆ¶è¦æ±‚ï¼š
- å¿…é¡»ä½¿ç”¨å¹¶ä¿ç•™æ ‡ç­¾ï¼š[FACT] [INFERENCE] [ASSUMPTION] [STRATEGY]
- ç»“è®ºå¿…é¡»åŸºäºè¾“å…¥æ•°æ®ï¼›æ²¡æœ‰æ•°æ®å°±æ˜ç¡®æ ‡æ³¨[ASSUMPTION]ï¼Œä¸è¦ç¼–é€ å…·ä½“æ•°å€¼ã€‚
- æŠ¥å‘Šå¿…é¡»åŒ…å«ï¼š1) Trade Area Intelligenceï¼ˆ1mi/3miï¼‰ 2) ç«å¯¹ä¸æ›¿ä»£ç»“æ„ 3) è½¬åŒ–æ¼æ–—è¯Šæ–­ 4) å¤©æ°”/å­£èŠ‚/äº¤é€šå½±å“ 5) 30/60/90å¤©åŠ¨ä½œæ¸…å•
- æŠ¥å‘Šè¯­è¨€ï¼š{"ç®€ä½“ä¸­æ–‡" if lang=="zh" else "English"}ã€‚æ ‡é¢˜ä¸æ®µè½ä¹Ÿè¦å¯¹åº”è¯­è¨€ã€‚
- å­—ä½“æ ¼å¼ï¼šç”¨Markdownæ ‡é¢˜/è¡¨æ ¼å‘ˆç°å…³é”®çŸ©é˜µï¼›é¿å…è¶…é•¿æ— ç»“æ„æ®µè½ã€‚
"""

    # ç”¨æˆ·æç¤ºï¼šæŠŠæ•°æ®å–‚ç»™æ¨¡å‹ï¼ˆçŸ­è€Œå…³é”®ï¼‰
    user = f"""
è¯·ä¸ºä»¥ä¸‹é¤å…ç”Ÿæˆã€Šå•†åœˆä¸å¢é•¿åˆ†ææŠ¥å‘Šã€‹ï¼Œé£æ ¼å¯¹é½æˆ‘æä¾›çš„æ ·æ¿ï¼ˆåâ€œéº¦è‚¯é”¡å¼â€ä½†ç›´ç™½å¯è½åœ°ï¼‰ã€‚

é¤å…ä¿¡æ¯ï¼ˆæ¥è‡ªGoogle Placesï¼‰ï¼š
- é—¨åº—ï¼š{name}
- åœ°å€ï¼š{address}
- åæ ‡ï¼š{lat:.5f},{lng:.5f}
- Googleè¯„åˆ†/è¯„è®ºæ•°ï¼š{bundle["google"].get("rating")} / {bundle["google"].get("user_ratings_total")}
- ç±»å‹ï¼š{bundle["google"].get("types")}
- ä»·æ ¼ç­‰çº§(price_level)ï¼š{bundle["google"].get("price_level")}
- è¥ä¸šçŠ¶æ€ï¼š{bundle["google"].get("business_status")}
- ç”µè¯ï¼š{bundle["google"].get("phone")}
- ç½‘ç«™ï¼š{bundle["google"].get("website")}

Yelpï¼ˆè‹¥åŒ¹é…åˆ°ï¼‰ï¼š
- YelpåŒ¹é…ï¼š{(bundle["yelp"].get("match") or {}).get("name")}
- Yelpè¯„åˆ†/è¯„è®ºæ•°ï¼š{(bundle["yelp"].get("details") or {}).get("rating")} / {(bundle["yelp"].get("details") or {}).get("review_count")}
- Yelpä»·ä½ï¼š{(bundle["yelp"].get("details") or {}).get("price")}
- Yelpç±»åˆ«ï¼š{[(c.get("title")) for c in ((bundle["yelp"].get("details") or {}).get("categories") or [])[:4]]}
- Yelpè¿‘3æ¡è¯„è®ºæ‘˜å½•ï¼ˆå¦‚æœ‰ï¼‰ï¼š
{[(r.get("text") or "")[:180] for r in ((bundle["yelp"].get("reviews") or {}).get("reviews") or [])[:3]]}

äººå£ä¸æ¶ˆè´¹èƒ½åŠ›ï¼ˆCensus ACS + TIGERï¼Œå¯èƒ½ä¸ºè¿‘ä¼¼ï¼‰ï¼š
- tractï¼š{census.get("tract_name")} (state_fips={census.get("state_fips")}, county_fips={census.get("county_fips")}, tract={census.get("tract")})
- tractäººå£ï¼š{census.get("tract_pop")}
- å®¶åº­æˆ·æ•°ï¼š{census.get("households")}
- å®¶åº­æ”¶å…¥ä¸­ä½æ•°ï¼ˆUSDï¼Œå¯èƒ½ä¸ºç©ºï¼‰ï¼š{census.get("median_household_income")}
- æ—è£”æ¯”ä¾‹ï¼ˆ%ï¼‰ï¼šWhite={census.get("pct_white")}, Asian={census.get("pct_asian")}, Hispanic={census.get("pct_hispanic")}
- 1mi/3mi åŠå¾„äººå£ä¼°ç®—ï¼ˆåŸºäºå¯†åº¦è¿‘ä¼¼ï¼Œä¸æ˜¯ç²¾ç¡®ç¯ç»Ÿè®¡ï¼‰ï¼š
{radius_stats}

æ­¥è¡Œ/äº¤é€šï¼ˆå¯é€‰WalkScoreï¼‰ï¼š
{bundle.get("walkscore")}

å¤©æ°”ï¼ˆNOAAé¢„æµ‹ + Meteostatå†å²365å¤©æ±‡æ€»ï¼‰ï¼š
- NOAAæœªæ¥é¢„æµ‹ï¼ˆç®€åŒ–6æ¡ï¼‰ï¼š
{noaa_simple}
- Meteostatå†å²æ±‡æ€»ï¼ˆ365å¤©ï¼‰ï¼š
{weather_summary}
è§£é‡Šæç¤ºï¼šMeteostatæ¸©åº¦ä¸ºæ‘„æ°ï¼Œprcpä¸ºæ¯«ç±³ã€‚

ç«å¯¹æ± ï¼ˆYelp/Googleå‘¨è¾¹æ£€ç´¢åˆå¹¶å»é‡ï¼Œæœ€å¤š18æ¡ï¼‰ï¼š
{competitors}

å¿…é¡»è¾“å‡ºçš„å…³é”®ç»“æ„ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
ä¸€ã€å•†åœˆäººå£ä¸æ¶ˆè´¹èƒ½åŠ›æ¨¡å‹ï¼ˆTrade Area Intelligenceï¼‰
- 1mi/3miï¼šäººå£ã€æ”¶å…¥ã€æ—è£”ï¼ˆå¦‚æœç¼ºå­—æ®µï¼Œç»™åŒºé—´[ASSUMPTION]å¹¶è§£é‡Šä¸ºä½•ï¼‰
- ç»™å‡ºâ€œæ½œåœ¨è®¢å•å®¹é‡æ¨¡å‹â€çš„å¯è®¡ç®—å…¬å¼ï¼Œå¹¶ç”¨ä½ ç»™çš„æ•°æ®/å‡è®¾ç®—å‡ºåŒºé—´

äºŒã€ç«å¯¹ä¸æ›¿ä»£æ€§ç»“æ„åˆ†æ
- ç«å¯¹å®šä¹‰ï¼šæŠ¢åŒä¸€é¡¿é¥­é¢„ç®—/åŒä¸€åœºæ™¯
- åˆ†A/B/Cç±»ï¼ˆç›´æ¥/æ›¿ä»£/ä½“éªŒå¤§åº—æˆ–ç›®çš„åœ°ï¼‰
- è‡³å°‘æŒ‘3-6ä¸ªç«å¯¹å†™â€œä¸ºä»€ä¹ˆä¼šæŠ¢å• + DTå¦‚ä½•ååˆ¶â€çš„ç»“æ„
- è¾“å‡ºä¸€ä¸ªé‡åŒ–çŸ©é˜µè¡¨ï¼ˆè¯„åˆ†/è¯„æ•°/å¿ƒæ™º/åœºæ™¯/ååˆ¶ç‚¹ï¼‰

ä¸‰ã€è½¬åŒ–æ¼æ–—è¯Šæ–­æ¨¡å‹
- è®¢å• = æ›å…‰ Ã— CTR Ã— CVR Ã— å¤è´­ç‡
- ç»™è¡Œä¸šå¥åº·å€¼åŒºé—´ï¼Œå¹¶ç»“åˆæœ¬åº—çº¿ä¸Šä¿¡ä»»ä¿¡å·ï¼ˆè¯„åˆ†/è¯„æ•°/è¯„è®ºå†…å®¹ï¼‰æ¨æ–­æ–­ç‚¹
- æ–­ç‚¹å¿…é¡»è½åˆ°â€œå¯æ“ä½œåŠ¨ä½œâ€

å››ã€å¤©æ°”/å­£èŠ‚/äº¤é€šå½±å“
- ç”¨Meteostaté›¨å¤©/é«˜æ¸©/ä½æ¸©å¤©æ•°æ¥è®ºè¯å­£èŠ‚æ€§
- ç»™â€œé›¨å¤©å¤–å–æå‡â€ä¹‹ç±»ç»“è®ºå¿…é¡»æ ‡[ASSUMPTION]ï¼Œå¹¶ç»™åˆç†åŒºé—´
- ç»™å‡ºå¯æ‰§è¡Œçš„è¿è¥åŠ¨ä½œï¼ˆèœå•/é…é€/æ—¶æ®µå®šä»·/ä¿ƒé”€ï¼‰

äº”ã€30/60/90å¤©è¡ŒåŠ¨æ¸…å•ï¼ˆå¿…é¡»é‡åŒ–KPIï¼‰
- æ¯æ¡åŠ¨ä½œï¼šç›®æ ‡æŒ‡æ ‡ã€é¢„æœŸå½±å“è·¯å¾„ã€æ‰§è¡Œæˆæœ¬ç­‰çº§ï¼ˆä½/ä¸­/é«˜ï¼‰
- ç›®æ ‡è¦å†™å¾—åƒå†…éƒ¨å†³ç­–ä¼šä½¿ç”¨çš„ç‰ˆæœ¬

è¾“å‡ºå¿…é¡»æ˜¯Markdownï¼ˆå¯ç›´æ¥å¯¼å‡ºPDFï¼‰ï¼Œä¸è¦è¾“å‡ºä»£ç ã€‚
"""

    return system.strip(), user.strip()


# -----------------------------
# PDF export
# -----------------------------
def markdown_to_pdf_bytes(markdown_text: str, title: str = "Report") -> bytes:
    """
    ä¼˜å…ˆï¼šweasyprintï¼ˆæ›´æ¼‚äº®ï¼‰
    å…œåº•ï¼šreportlabï¼ˆä¿è¯èƒ½å¯¼å‡ºï¼‰
    """
    # Try WeasyPrint
    try:
        import markdown2
        from weasyprint import HTML, CSS

        html_body = markdown2.markdown(markdown_text, extras=["tables", "fenced-code-blocks"])
        html = f"""
        <html>
          <head>
            <meta charset="utf-8">
            <style>
              body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Arial, "Noto Sans CJK SC", "PingFang SC", "Microsoft YaHei", sans-serif; line-height: 1.35; }}
              h1, h2, h3 {{ margin: 0.6em 0 0.3em; }}
              table {{ border-collapse: collapse; width: 100%; margin: 0.6em 0; }}
              th, td {{ border: 1px solid #ddd; padding: 6px 8px; font-size: 12px; }}
              th {{ background: #f5f5f5; }}
              code {{ font-family: ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 11px; }}
              .meta {{ color: #666; font-size: 12px; }}
            </style>
          </head>
          <body>
            {html_body}
          </body>
        </html>
        """
        pdf = HTML(string=html).write_pdf(stylesheets=[CSS(string="")])
        return pdf
    except Exception:
        pass

    # Fallback: ReportLab simple
    from reportlab.lib.pagesizes import letter
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from reportlab.pdfgen import canvas

    # Optional: load a CJK font if available in system (best effort)
    # If you have a font file, set FONT_PATH env to it.
    font_name = "Helvetica"
    font_path = os.getenv("FONT_PATH", "")
    if font_path and os.path.exists(font_path):
        try:
            pdfmetrics.registerFont(TTFont("CustomFont", font_path))
            font_name = "CustomFont"
        except Exception:
            font_name = "Helvetica"

    import io
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=letter)
    width, height = letter
    c.setTitle(title)

    x = 50
    y = height - 50
    c.setFont(font_name, 10)

    # naive wrap lines (Markdown shown as plain text in fallback)
    for raw_line in markdown_text.splitlines():
        line = raw_line.strip("\n")
        if not line:
            y -= 12
            continue
        # wrap
        for seg in wrap_text(line, max_chars=95):
            if y < 60:
                c.showPage()
                c.setFont(font_name, 10)
                y = height - 50
            c.drawString(x, y, seg)
            y -= 12

    c.save()
    buffer.seek(0)
    return buffer.read()


def wrap_text(s: str, max_chars: int = 90) -> List[str]:
    out = []
    while len(s) > max_chars:
        out.append(s[:max_chars])
        s = s[max_chars:]
    out.append(s)
    return out


# -----------------------------
# UI
# -----------------------------
st.title("AuraInsight Â· é¤å…å•†åœˆä¸å¢é•¿åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨")
st.caption("è¾“å…¥åœ°å€/åº—å â†’ é€‰ä¸­æ­£ç¡®å•†å®¶ â†’ æ‹‰å–å…¬å¼€æ•°æ® â†’ ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Šï¼ˆæ”¯æŒä¸­è‹± & PDFå¯¼å‡ºï¼‰")

with st.sidebar:
    st.header("è®¾ç½®")
    lang = st.selectbox("æŠ¥å‘Šè¯­è¨€", ["ä¸­æ–‡", "English"], index=0)
    lang_code = "zh" if lang == "ä¸­æ–‡" else "en"

    st.subheader("API çŠ¶æ€")
    st.write("Google Places:", "âœ…" if GOOGLE_MAPS_API_KEY else "âŒ")
    st.write("Yelp:", "âœ…" if YELP_API_KEY else "âŒ")
    st.write("OpenAI:", "âœ…" if OPENAI_API_KEY else "âŒ")
    st.write("Census key:", "âœ…" if CENSUS_API_KEY else "âš ï¸(å¯é€‰)")
    st.write("WalkScore:", "âœ…" if WALKSCORE_API_KEY else "âš ï¸(å¯é€‰)")
    st.divider()
    st.markdown(
        """
**å¤©æ°”æ•°æ®æ¥æº**  
- NOAA (forecast) + Meteostat (å†å²365å¤©)  
æ— éœ€æ³¨å†Œï¼Œé€‚åˆåšâ€œé›¨å¤©/é«˜æ¸©/å­£èŠ‚æ€§â€çš„é‡åŒ–åˆ†æã€‚
"""
    )

query = st.text_input("é¤å…åœ°å€ / åº—åï¼ˆå»ºè®®ï¼šåº—å + åŸå¸‚ï¼‰", value="")
colA, colB = st.columns([1, 1])

if "candidates" not in st.session_state:
    st.session_state.candidates = []
if "selected_place_id" not in st.session_state:
    st.session_state.selected_place_id = None
if "report_zh" not in st.session_state:
    st.session_state.report_zh = None
if "report_en" not in st.session_state:
    st.session_state.report_en = None
if "bundle" not in st.session_state:
    st.session_state.bundle = None


with colA:
    if st.button("ğŸ” æœç´¢åŒ¹é…å•†å®¶", use_container_width=True, disabled=not query.strip()):
        try:
            with st.spinner("Google Places æœç´¢ä¸­..."):
                cands = google_text_search(query.strip())
            if not cands:
                st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ç»“æœï¼Œè¯·å°è¯•æ›´å…·ä½“çš„è¾“å…¥ï¼ˆåº—å + åŸå¸‚ + å·ï¼‰ã€‚")
            st.session_state.candidates = cands
            st.session_state.selected_place_id = None
            st.session_state.report_zh = None
            st.session_state.report_en = None
            st.session_state.bundle = None
        except Exception as e:
            st.error(f"æœç´¢å¤±è´¥ï¼š{e}")

with colB:
    clear = st.button("ğŸ§¹ æ¸…ç©º", use_container_width=True)
    if clear:
        st.session_state.candidates = []
        st.session_state.selected_place_id = None
        st.session_state.report_zh = None
        st.session_state.report_en = None
        st.session_state.bundle = None
        st.rerun()

# Candidate selection
if st.session_state.candidates:
    st.subheader("é€‰æ‹©æ­£ç¡®çš„å•†å®¶ï¼ˆç¡®è®¤åå†å¼€å§‹åˆ†æï¼‰")
    labels = []
    for i, c in enumerate(st.session_state.candidates):
        labels.append(
            f"{i+1}. {c.name} | {c.address} | â­{c.rating or 'NA'} ({c.user_ratings_total or 'NA'})"
        )
    idx = st.selectbox("åŒ¹é…ç»“æœ", list(range(len(labels))), format_func=lambda i: labels[i])
    chosen = st.session_state.candidates[idx]
    st.session_state.selected_place_id = chosen.place_id

    st.info(f"å·²é€‰æ‹©ï¼š**{chosen.name}**  â€”  {chosen.address}")

    # Show quick map
    try:
        st.map(pd.DataFrame([{"lat": chosen.lat, "lon": chosen.lng}]).rename(columns={"lon": "lon"}))
    except Exception:
        pass

    # Generate report
    if st.button("ğŸš€ å¼€å§‹åˆ†æå¹¶ç”ŸæˆæŠ¥å‘Š", type="primary", use_container_width=True):
        if not OPENAI_API_KEY:
            st.error("ç¼ºå°‘ OPENAI_API_KEYï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚")
        else:
            try:
                with st.spinner("æ‹‰å–æ•°æ®ä¸­ï¼ˆäººå£/ç«å“/å¤©æ°”ï¼‰..."):
                    place = google_place_details(chosen.place_id)
                    bundle = build_data_bundle(place)
                    st.session_state.bundle = bundle

                with st.spinner("è°ƒç”¨æ¨¡å‹ç”ŸæˆæŠ¥å‘Šï¼ˆé•¿æ–‡ï¼‰..."):
                    sys_prompt, user_prompt = make_report_prompt(bundle, lang="zh")  # å…ˆç”Ÿæˆä¸­æ–‡åŸºç¨¿æœ€ç¨³
                    report_zh = openai_chat(sys_prompt, user_prompt, temperature=0.25, max_tokens=3500)
                    st.session_state.report_zh = report_zh

                # è‹¥ç”¨æˆ·æƒ³è‹±æ–‡ï¼šç”¨ç¿»è¯‘ï¼ˆæ›´ç¨³å®šï¼Œä¸ä¼šè·‘æ ¼å¼ï¼‰
                if lang_code == "en":
                    with st.spinner("ç¿»è¯‘æˆè‹±æ–‡..."):
                        st.session_state.report_en = translate_text(report_zh, "en")

                st.success("æŠ¥å‘Šç”Ÿæˆå®Œæˆã€‚")
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

# Display report
report_to_show = None
if lang_code == "zh" and st.session_state.report_zh:
    report_to_show = st.session_state.report_zh
elif lang_code == "en":
    if st.session_state.report_en:
        report_to_show = st.session_state.report_en
    elif st.session_state.report_zh:
        # è¿˜æ²¡ç¿»è¯‘å°±ç°åœºç¿»è¯‘
        try:
            with st.spinner("ç¿»è¯‘æˆè‹±æ–‡..."):
                st.session_state.report_en = translate_text(st.session_state.report_zh, "en")
            report_to_show = st.session_state.report_en
        except Exception as e:
            st.error(f"ç¿»è¯‘å¤±è´¥ï¼š{e}")
            report_to_show = st.session_state.report_zh

if report_to_show:
    st.divider()
    st.subheader("ç”Ÿæˆçš„æŠ¥å‘Šï¼ˆå¯ç›´æ¥å¯¼å‡ºPDFï¼‰")
    st.markdown(report_to_show)

    # Download PDF
    try:
        place_name = ""
        if st.session_state.bundle and st.session_state.bundle.get("place"):
            place_name = st.session_state.bundle["place"].get("name") or "Restaurant"
        file_name = f"{place_name}_TradeArea_Growth_Report_{lang_code}.pdf".replace(" ", "_")
        pdf_bytes = markdown_to_pdf_bytes(report_to_show, title=file_name)
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ PDF",
            data=pdf_bytes,
            file_name=file_name,
            mime="application/pdf",
            use_container_width=True,
        )
    except Exception as e:
        st.warning(f"PDFå¯¼å‡ºå¤±è´¥ï¼ˆå¯å…ˆå¤åˆ¶Markdownï¼‰ï¼š{e}")

# Debug panel (optional)
with st.expander("ï¼ˆå¯é€‰ï¼‰æŸ¥çœ‹åŸå§‹æ•°æ®åŒ…/è°ƒè¯•", expanded=False):
    st.write("bundle keys:", list((st.session_state.bundle or {}).keys()))
    st.json(st.session_state.bundle or {})
